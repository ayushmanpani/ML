{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecf60b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PERSONAL\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat \n",
    "import numpy as np \n",
    "from scipy.optimize import minimize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab58db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise(a, b): \n",
    "    epsilon = 0.15\n",
    "    c = np.random.rand(a, b + 1) * (2 * epsilon) - epsilon   # Randomly initialises values of thetas between [-epsilon, +epsilon]\n",
    "    return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3aa813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Theta1, Theta2, Theta3, X): \n",
    "    m = X.shape[0] \n",
    "    one_matrix = np.ones((m, 1)) \n",
    "    X = np.append(one_matrix, X, axis=1) # Adding bias unit to first layer \n",
    "    a0 = X \n",
    "    z1 = np.dot(X, Theta1.transpose()) \n",
    "    a1 = 1 / (1 + np.exp(-z1)) # Activation for second layer \n",
    "    one_matrix = np.ones((m, 1)) \n",
    "    a1 = np.append(one_matrix, a1, axis=1) # Adding bias unit to hidden layer 1 \n",
    "    z2 = np.dot(a1, Theta2.transpose()) \n",
    "    a2 = 1 / (1 + np.exp(-z2))\n",
    "    one_matrix = np.ones((m, 1)) \n",
    "    a2 = np.append(one_matrix, a2, axis=1) # Adding bias unit to hidden layer 2\n",
    "    z3 = np.dot(a2, Theta3.transpose()) \n",
    "    a3 = 1 / (1 + np.exp(-z3)) # Activation for third layer \n",
    "    p = (np.argmax(a3, axis=1)) # Predicting the class on the basis of max value of hypothesis \n",
    "    return p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9db17081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(nn_params, input_layer_size, hidden_layer1_size, hidden_layer2_size, num_labels, X, y, lamb): \n",
    "    # Weights are split back to Theta1, Theta2 \n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer1_size * (input_layer_size + 1)],(hidden_layer1_size, input_layer_size + 1))\n",
    "    strt_indx_theta2=hidden_layer1_size * (input_layer_size + 1)\n",
    "    Theta2 = np.reshape(nn_params[strt_indx_theta2:strt_indx_theta2+(hidden_layer2_size * (hidden_layer1_size + 1))],(hidden_layer2_size, hidden_layer1_size + 1))\n",
    "    strt_indx_theta3=strt_indx_theta2 + (hidden_layer2_size * (hidden_layer1_size + 1))\n",
    "    Theta3 = np.reshape(nn_params[strt_indx_theta3:],(num_labels, hidden_layer2_size + 1))\n",
    "\n",
    "    # Forward propagation \n",
    "    m = X.shape[0] \n",
    "    one_matrix = np.ones((m, 1)) \n",
    "    X = np.append(one_matrix, X, axis=1) # Adding bias unit to first layer \n",
    "    a0 = X \n",
    "    z1 = np.dot(X, Theta1.transpose()) \n",
    "    a1 = 1 / (1 + np.exp(-z1)) # Activation for second layer \n",
    "    one_matrix = np.ones((m, 1)) \n",
    "    a1 = np.append(one_matrix, a1, axis=1) # Adding bias unit to hidden layer 1 \n",
    "    z2 = np.dot(a1, Theta2.transpose()) \n",
    "    a2 = 1 / (1 + np.exp(-z2))\n",
    "    one_matrix = np.ones((m, 1)) \n",
    "    a2 = np.append(one_matrix, a2, axis=1) # Adding bias unit to hidden layer 2\n",
    "    z3 = np.dot(a2, Theta3.transpose()) \n",
    "    a3 = 1 / (1 + np.exp(-z3)) #Activation for third layer\n",
    "\n",
    "    #one-hot encoding:\n",
    "    y_vect = np.zeros((m, 10)) \n",
    "    for i in range(m): \n",
    "        y_vect[i, int(y[i])] = 1\n",
    "\n",
    "    # Calculating cost function \n",
    "    J = (1 / m) * (np.sum(np.sum(-y_vect * np.log(a3) - (1 - y_vect) * np.log(1 - a3)))) + \n",
    "    (lamb / (2 * m)) * (sum(sum(pow(Theta1[:, 1:], 2))) + sum(sum(pow(Theta2[:, 1:], 2))) + sum(sum(pow(Theta3[:, 1:], 2)))) \n",
    "\n",
    "    # backprop \n",
    "    Delta3 = a3 - y_vect \n",
    "    Delta2 = np.dot(Delta3, Theta3) * a2 * (1 - a2) \n",
    "    Delta2 = Delta2[:, 1:]\n",
    "    Delta1 = np.dot(Delta2, Theta2) * a1 * (1 - a1) \n",
    "    Delta1 = Delta1[:, 1:]\n",
    "\n",
    "    #gradient calc\n",
    "    Theta1[:, 0] = 0\n",
    "    Theta1_grad = (1 / m) * np.dot(Delta1.transpose(), a0) + (lamb / m) * Theta1 \n",
    "    Theta2[:, 0] = 0\n",
    "    Theta2_grad = (1 / m) * np.dot(Delta2.transpose(), a1) + (lamb / m) * Theta2 \n",
    "    Theta1[:, 0] = 0\n",
    "    Theta3_grad = (1 / m) * np.dot(Delta3.transpose(), a2) + (lamb / m) * Theta3\n",
    "    grad = np.concatenate((Theta1_grad.flatten(), Theta2_grad.flatten(), Theta3_grad.flatten())) \n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad8ac499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PERSONAL\\AppData\\Local\\Temp\\ipykernel_12556\\3904544209.py:31: RuntimeWarning: divide by zero encountered in log\n",
      "  J = (1 / m) * (np.sum(np.sum(-y_vect * np.log(a3) - (1 - y_vect) * np.log(1 - a3)))) + (lamb / (2 * m)) * (sum(sum(pow(Theta1[:, 1:], 2))) + sum(sum(pow(Theta2[:, 1:], 2))) + sum(sum(pow(Theta3[:, 1:], 2))))\n",
      "C:\\Users\\PERSONAL\\AppData\\Local\\Temp\\ipykernel_12556\\3904544209.py:31: RuntimeWarning: invalid value encountered in multiply\n",
      "  J = (1 / m) * (np.sum(np.sum(-y_vect * np.log(a3) - (1 - y_vect) * np.log(1 - a3)))) + (lamb / (2 * m)) * (sum(sum(pow(Theta1[:, 1:], 2))) + sum(sum(pow(Theta2[:, 1:], 2))) + sum(sum(pow(Theta3[:, 1:], 2))))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12556\\3775403872.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# Calling minimize function to minimize cost function and to train weights using quasi-newton method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m results = minimize(neural_network, x0=initial_nn_params, args=myargs,  \n\u001b[0m\u001b[0;32m     42\u001b[0m           options={'disp': True, 'maxiter': maxiter}, method=\"L-BFGS-B\", jac=True) \n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    697\u001b[0m                                  **options)\n\u001b[0;32m    698\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    700\u001b[0m                                callback=callback, **options)\n\u001b[0;32m    701\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[1;31m# Make sure the function returns a true scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12556\\3904544209.py\u001b[0m in \u001b[0;36mneural_network\u001b[1;34m(nn_params, input_layer_size, hidden_layer1_size, hidden_layer2_size, num_labels, X, y, lamb)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Adding bias unit to first layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0ma0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTheta1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Activation for second layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mone_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loading mat file \n",
    "data = loadmat('mnist-original.mat') \n",
    "  \n",
    "# Extracting features from mat file \n",
    "X = data['data'] \n",
    "X = X.transpose() \n",
    "  \n",
    "# Normalizing the data \n",
    "X = X / 255\n",
    "  \n",
    "# Extracting labels from mat file \n",
    "y = data['label'] \n",
    "y = y.flatten() \n",
    "  \n",
    "# Splitting data into training set with 60,000 examples \n",
    "X_train = X[:60000, :] \n",
    "y_train = y[:60000] \n",
    "  \n",
    "# Splitting data into testing set with 10,000 examples \n",
    "X_test = X[60000:, :] \n",
    "y_test = y[60000:] \n",
    "  \n",
    "m = X.shape[0] \n",
    "input_layer_size = 784  # Images are of (28 X 28) px so there will be 784 features \n",
    "hidden_layer1_size = 100\n",
    "hidden_layer2_size = 200\n",
    "num_labels = 10  # There are 10 classes [0, 9] \n",
    "  \n",
    "# Randomly initialising Thetas \n",
    "initial_Theta1 = initialise(hidden_layer1_size, input_layer_size)\n",
    "initial_Theta2 = initialise(hidden_layer2_size, hidden_layer1_size)\n",
    "initial_Theta3 = initialise(num_labels, hidden_layer2_size) \n",
    "  \n",
    "# Unrolling parameters into a single column vector \n",
    "initial_nn_params = np.concatenate((initial_Theta1.flatten(), initial_Theta2.flatten(), initial_Theta3.flatten())) \n",
    "maxiter = 500\n",
    "lambda_reg = 0.1  # To avoid overfitting \n",
    "myargs = (input_layer_size, hidden_layer1_size, hidden_layer2_size, num_labels, X_train, y_train, lambda_reg) \n",
    "  \n",
    "# Calling minimize function to minimize cost function and to train weights using quasi-newton method \n",
    "results = minimize(neural_network, x0=initial_nn_params, args=myargs,  \n",
    "          options={'disp': True, 'maxiter': maxiter}, method=\"L-BFGS-B\", jac=True) \n",
    "  \n",
    "nn_params = results[\"x\"]  # Trained Theta is extracted \n",
    "  \n",
    "# Weights are split back to Theta1, Theta2, Theta3 \n",
    "Theta1 = np.reshape(nn_params[:hidden_layer1_size * (input_layer_size + 1)],(hidden_layer1_size, input_layer_size + 1))\n",
    "strt_indx_theta2=hidden_layer1_size * (input_layer_size + 1)\n",
    "Theta2 = np.reshape(nn_params[strt_indx_theta2:strt_indx_theta2+(hidden_layer2_size * (hidden_layer1_size + 1))],(hidden_layer2_size, hidden_layer1_size + 1))\n",
    "strt_indx_theta3=strt_indx_theta2 + (hidden_layer2_size * (hidden_layer1_size + 1))\n",
    "Theta3 = np.reshape(nn_params[strt_indx_theta3:],(num_labels, hidden_layer2_size + 1))# shape = (10, 101) \n",
    "  \n",
    "# Checking test set accuracy of our model \n",
    "pred = predict(Theta1, Theta2, Theta3, X_test) \n",
    "print('Test Set Accuracy: {:f}'.format((np.mean(pred == y_test) * 100))) \n",
    "  \n",
    "# Checking train set accuracy of our model \n",
    "pred = predict(Theta1, Theta2, Theta3, X_train) \n",
    "print('Training Set Accuracy: {:f}'.format((np.mean(pred == y_train) * 100))) \n",
    "  \n",
    "# Evaluating precision of our model \n",
    "true_positive = 0\n",
    "for i in range(len(pred)): \n",
    "    if pred[i] == y_train[i]: \n",
    "        true_positive += 1\n",
    "false_positive = len(y_train) - true_positive \n",
    "print('Precision =', true_positive/(true_positive + false_positive)) \n",
    "  \n",
    "# Saving Thetas in .txt file \n",
    "np.savetxt('Theta1.txt', Theta1, delimiter=' ') \n",
    "np.savetxt('Theta2.txt', Theta2, delimiter=' ')\n",
    "np.savetxt('Theta3.txt', Theta3, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "916875a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import numpy as np \n",
    "from PIL import ImageGrab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4212f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Tk() \n",
    "window.title(\"Handwritten digit recognition\") \n",
    "l1 = Label() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "655f01ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyProject(): \n",
    "    global l1 \n",
    "  \n",
    "    widget = cv \n",
    "    # Setting co-ordinates of canvas \n",
    "    x = window.winfo_rootx() + widget.winfo_x() \n",
    "    y = window.winfo_rooty() + widget.winfo_y() \n",
    "    x1 = x + widget.winfo_width() \n",
    "    y1 = y + widget.winfo_height() \n",
    "  \n",
    "    # Image is captured from canvas and is resized to (28 X 28) px \n",
    "    img = ImageGrab.grab().crop((x, y, x1, y1)).resize((28, 28)) \n",
    "  \n",
    "    # Converting rgb to grayscale image \n",
    "    img = img.convert('L') \n",
    "  \n",
    "    # Extracting pixel matrix of image and converting it to a vector of (1, 784) \n",
    "    x = np.asarray(img) \n",
    "    vec = np.zeros((1, 784)) \n",
    "    k = 0\n",
    "    for i in range(28): \n",
    "        for j in range(28): \n",
    "            vec[0][k] = x[i][j] \n",
    "            k += 1\n",
    "  \n",
    "    # Loading Thetas \n",
    "    Theta1 = np.loadtxt('Theta1.txt') \n",
    "    Theta2 = np.loadtxt('Theta2.txt')\n",
    "    Theta3 = np.loadtxt('Theta3.txt')\n",
    "  \n",
    "    # Calling function for prediction \n",
    "    pred = predict(Theta1, Theta2, Theta3, vec / 255) \n",
    "  \n",
    "    # Displaying the result \n",
    "    l1 = Label(window, text=\"Digit = \" + str(pred[0]), font=('Algerian', 20)) \n",
    "    l1.place(x=230, y=420) \n",
    "  \n",
    "  \n",
    "lastx, lasty = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e896fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_widget(): \n",
    "    global cv, l1 \n",
    "    cv.delete(\"all\") \n",
    "    l1.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc2f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_activation(event): \n",
    "    global lastx, lasty \n",
    "    cv.bind('<B1-Motion>', draw_lines) \n",
    "    lastx, lasty = event.x, event.y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5658ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(event): \n",
    "    global lastx, lasty \n",
    "    x, y = event.x, event.y \n",
    "    cv.create_line((lastx, lasty, x, y), width=30, fill='white', capstyle=ROUND, smooth=TRUE, splinesteps=12) \n",
    "    lastx, lasty = x, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97aaa31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = Label(window, text=\"Handwritten Digit Recoginition\", font=('Algerian', 25), fg=\"blue\") \n",
    "L1.place(x=35, y=10) \n",
    "  \n",
    "# Button to clear canvas \n",
    "b1 = Button(window, text=\"1. Clear Canvas\", font=('Algerian', 15), bg=\"orange\", fg=\"black\", command=clear_widget) \n",
    "b1.place(x=120, y=370) \n",
    "  \n",
    "# Button to predict digit drawn on canvas \n",
    "b2 = Button(window, text=\"2. Prediction\", font=('Algerian', 15), bg=\"white\", fg=\"red\", command=MyProject) \n",
    "b2.place(x=320, y=370) \n",
    "  \n",
    "# Setting properties of canvas \n",
    "cv = Canvas(window, width=350, height=290, bg='black') \n",
    "cv.place(x=120, y=70) \n",
    "  \n",
    "cv.bind('<Button-1>', event_activation) \n",
    "window.geometry(\"600x500\") \n",
    "window.mainloop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c57931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
